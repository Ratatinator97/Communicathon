(function (global, factory) {
    typeof exports === 'object' && typeof module !== 'undefined' ? factory(exports, require('@angular/core')) :
    typeof define === 'function' && define.amd ? define('@kamiazya/ngx-speech-synthesis', ['exports', '@angular/core'], factory) :
    (factory((global.kamiazya = global.kamiazya || {}, global.kamiazya['ngx-speech-synthesis'] = {}),global.ng.core));
}(this, (function (exports,i0) { 'use strict';

    /**
     * @fileoverview added by tsickle
     * @suppress {checkTypes,extraRequire,missingReturn,unusedPrivateMembers,uselessCode} checked by tsc
     */
    /** @type {?} */
    var Lang = new i0.InjectionToken('speech-synthesis.lang');
    /** @type {?} */
    var Voice = new i0.InjectionToken('speech-synthesis.voice');
    /** @type {?} */
    var Volume = new i0.InjectionToken('speech-synthesis.volume');
    /** @type {?} */
    var Rate = new i0.InjectionToken('speech-synthesis.rate');
    /** @type {?} */
    var Pitch = new i0.InjectionToken('speech-synthesis.pitch');
    /** @type {?} */
    var OnStartHandler = new i0.InjectionToken('speech-synthesis.onstart');
    /** @type {?} */
    var OnEndHandler = new i0.InjectionToken('speech-synthesis.onend');
    /** @type {?} */
    var OnErrorHandler = new i0.InjectionToken('speech-synthesis.onerror');
    /** @type {?} */
    var OnPauseHandler = new i0.InjectionToken('speech-synthesis.onpause');
    /** @type {?} */
    var OnResumeHandler = new i0.InjectionToken('speech-synthesis.onresume');
    /** @type {?} */
    var OnMarkHandler = new i0.InjectionToken('speech-synthesis.onmark');
    /** @type {?} */
    var OnBoundaryHandler = new i0.InjectionToken('speech-synthesis.onboundary');
    /** @type {?} */
    var Params = new i0.InjectionToken('speech-synthesis.params');
    /** @type {?} */
    var Config = new i0.InjectionToken('speech-synthesis.config');

    /**
     * @fileoverview added by tsickle
     * @suppress {checkTypes,extraRequire,missingReturn,unusedPrivateMembers,uselessCode} checked by tsc
     */
    var SpeechSynthesisService = /** @class */ (function () {
        function SpeechSynthesisService() {
            this.internal = window.speechSynthesis;
        }
        Object.defineProperty(SpeechSynthesisService.prototype, "pending", {
            /**
             * This attribute is true if the queue for
             * the global SpeechSynthesis instance contains any utterances
             * which have not started speaking.
             */
            get: /**
             * This attribute is true if the queue for
             * the global SpeechSynthesis instance contains any utterances
             * which have not started speaking.
             * @return {?}
             */ function () {
                return this.internal.pending;
            },
            enumerable: true,
            configurable: true
        });
        Object.defineProperty(SpeechSynthesisService.prototype, "speaking", {
            /**
             * This attribute is true if an utterance is being spoken.
             * Specifically if an utterance has begun being spoken
             * and has not completed being spoken.
             * This is independent of whether the global SpeechSynthesis instance is
             * in the paused state.
             */
            get: /**
             * This attribute is true if an utterance is being spoken.
             * Specifically if an utterance has begun being spoken
             * and has not completed being spoken.
             * This is independent of whether the global SpeechSynthesis instance is
             * in the paused state.
             * @return {?}
             */ function () {
                return this.internal.speaking;
            },
            enumerable: true,
            configurable: true
        });
        Object.defineProperty(SpeechSynthesisService.prototype, "paused", {
            /**
             * This attribute is true when the global SpeechSynthesis instance is
             * in the paused state.
             * This state is independent of whether anything is in the queue.
             * The default state of a the global SpeechSynthesis instance
             * for a new window is the non-paused state.
             */
            get: /**
             * This attribute is true when the global SpeechSynthesis instance is
             * in the paused state.
             * This state is independent of whether anything is in the queue.
             * The default state of a the global SpeechSynthesis instance
             * for a new window is the non-paused state.
             * @return {?}
             */ function () {
                return this.internal.paused;
            },
            enumerable: true,
            configurable: true
        });
        Object.defineProperty(SpeechSynthesisService.prototype, "onvoiceschanged", {
            /**
             * Fired when the contents of the SpeechSynthesisVoiceList,
             * that the getVoices method will return, have changed.
             * Examples include: server-side synthesis where the list is determined asynchronously,
             * or when client-side voices are installed/uninstalled.
             */
            set: /**
             * Fired when the contents of the SpeechSynthesisVoiceList,
             * that the getVoices method will return, have changed.
             * Examples include: server-side synthesis where the list is determined asynchronously,
             * or when client-side voices are installed/uninstalled.
             * @param {?} handler
             * @return {?}
             */ function (handler) {
                this.internal.onvoiceschanged = handler;
            },
            enumerable: true,
            configurable: true
        });
        /**
         * This method appends the SpeechSynthesisUtterance object utterance
         * to the end of the queue for the global SpeechSynthesis instance.
         * It does not change the paused state of the SpeechSynthesis instance.
         * If the SpeechSynthesis instance is paused, it remains paused.
         * If it is not paused and no other utterances are in the queue,
         * then this utterance is spoken immediately, else this utterance is queued
         * to begin speaking after the other utterances in the queue have been spoken.
         * If changes are made to the SpeechSynthesisUtterance object after calling
         * this method and prior to the corresponding end or error event,
         * it is not defined whether those changes will affect what is spoken,
         * and those changes may cause an error to be returned.
         * The SpeechSynthesis object takes exclusive ownership of the SpeechSynthesisUtterance object.
         * Passing it as a speak() argument to another SpeechSynthesis object should throw an exception.
         * (For example, two frames may have the same origin and each will contain a SpeechSynthesis object.)
         */
        /**
         * This method appends the SpeechSynthesisUtterance object utterance
         * to the end of the queue for the global SpeechSynthesis instance.
         * It does not change the paused state of the SpeechSynthesis instance.
         * If the SpeechSynthesis instance is paused, it remains paused.
         * If it is not paused and no other utterances are in the queue,
         * then this utterance is spoken immediately, else this utterance is queued
         * to begin speaking after the other utterances in the queue have been spoken.
         * If changes are made to the SpeechSynthesisUtterance object after calling
         * this method and prior to the corresponding end or error event,
         * it is not defined whether those changes will affect what is spoken,
         * and those changes may cause an error to be returned.
         * The SpeechSynthesis object takes exclusive ownership of the SpeechSynthesisUtterance object.
         * Passing it as a speak() argument to another SpeechSynthesis object should throw an exception.
         * (For example, two frames may have the same origin and each will contain a SpeechSynthesis object.)
         * @param {?} utterance
         * @return {?}
         */
        SpeechSynthesisService.prototype.speak = /**
         * This method appends the SpeechSynthesisUtterance object utterance
         * to the end of the queue for the global SpeechSynthesis instance.
         * It does not change the paused state of the SpeechSynthesis instance.
         * If the SpeechSynthesis instance is paused, it remains paused.
         * If it is not paused and no other utterances are in the queue,
         * then this utterance is spoken immediately, else this utterance is queued
         * to begin speaking after the other utterances in the queue have been spoken.
         * If changes are made to the SpeechSynthesisUtterance object after calling
         * this method and prior to the corresponding end or error event,
         * it is not defined whether those changes will affect what is spoken,
         * and those changes may cause an error to be returned.
         * The SpeechSynthesis object takes exclusive ownership of the SpeechSynthesisUtterance object.
         * Passing it as a speak() argument to another SpeechSynthesis object should throw an exception.
         * (For example, two frames may have the same origin and each will contain a SpeechSynthesis object.)
         * @param {?} utterance
         * @return {?}
         */
            function (utterance) {
                this.internal.speak(utterance);
            };
        /**
         * This method removes all utterances from the queue.
         * If an utterance is being spoken, speaking ceases immediately.
         * This method does not change the paused state of the global SpeechSynthesis instance.
         */
        /**
         * This method removes all utterances from the queue.
         * If an utterance is being spoken, speaking ceases immediately.
         * This method does not change the paused state of the global SpeechSynthesis instance.
         * @return {?}
         */
        SpeechSynthesisService.prototype.cancel = /**
         * This method removes all utterances from the queue.
         * If an utterance is being spoken, speaking ceases immediately.
         * This method does not change the paused state of the global SpeechSynthesis instance.
         * @return {?}
         */
            function () {
                this.internal.cancel();
            };
        /**
         * This method puts the global SpeechSynthesis instance into the paused state.
         * If an utterance was being spoken, it pauses mid-utterance.
         * (If called when the SpeechSynthesis instance was already in the paused state, it does nothing.)
         */
        /**
         * This method puts the global SpeechSynthesis instance into the paused state.
         * If an utterance was being spoken, it pauses mid-utterance.
         * (If called when the SpeechSynthesis instance was already in the paused state, it does nothing.)
         * @return {?}
         */
        SpeechSynthesisService.prototype.pause = /**
         * This method puts the global SpeechSynthesis instance into the paused state.
         * If an utterance was being spoken, it pauses mid-utterance.
         * (If called when the SpeechSynthesis instance was already in the paused state, it does nothing.)
         * @return {?}
         */
            function () {
                this.internal.pause();
            };
        /**
         * This method puts the global SpeechSynthesis instance into the non-paused state.
         * If an utterance was speaking, it continues speaking the utterance
         * at the point at which it was paused, else it begins speaking
         * the next utterance in the queue (if any).
         * (If called when the SpeechSynthesis instance was already in the non-paused state, it does nothing.)
         */
        /**
         * This method puts the global SpeechSynthesis instance into the non-paused state.
         * If an utterance was speaking, it continues speaking the utterance
         * at the point at which it was paused, else it begins speaking
         * the next utterance in the queue (if any).
         * (If called when the SpeechSynthesis instance was already in the non-paused state, it does nothing.)
         * @return {?}
         */
        SpeechSynthesisService.prototype.resume = /**
         * This method puts the global SpeechSynthesis instance into the non-paused state.
         * If an utterance was speaking, it continues speaking the utterance
         * at the point at which it was paused, else it begins speaking
         * the next utterance in the queue (if any).
         * (If called when the SpeechSynthesis instance was already in the non-paused state, it does nothing.)
         * @return {?}
         */
            function () {
                this.internal.resume();
            };
        /**
         * This method returns the available voices.
         * It is user agent dependent which voices are available.
         * If there are no voices available, or if the the list of available voices
         * is not yet known (for example: server-side synthesis where the list is determined asynchronously),
         * then this method must return a SpeechSynthesisVoiceList of length zero.
         */
        /**
         * This method returns the available voices.
         * It is user agent dependent which voices are available.
         * If there are no voices available, or if the the list of available voices
         * is not yet known (for example: server-side synthesis where the list is determined asynchronously),
         * then this method must return a SpeechSynthesisVoiceList of length zero.
         * @return {?}
         */
        SpeechSynthesisService.prototype.getVoices = /**
         * This method returns the available voices.
         * It is user agent dependent which voices are available.
         * If there are no voices available, or if the the list of available voices
         * is not yet known (for example: server-side synthesis where the list is determined asynchronously),
         * then this method must return a SpeechSynthesisVoiceList of length zero.
         * @return {?}
         */
            function () {
                return this.internal.getVoices();
            };
        SpeechSynthesisService.decorators = [
            { type: i0.Injectable, args: [{
                        providedIn: 'root'
                    },] }
        ];
        /** @nocollapse */
        SpeechSynthesisService.ctorParameters = function () { return []; };
        /** @nocollapse */ SpeechSynthesisService.ngInjectableDef = i0.defineInjectable({ factory: function SpeechSynthesisService_Factory() { return new SpeechSynthesisService(); }, token: SpeechSynthesisService, providedIn: "root" });
        return SpeechSynthesisService;
    }());

    /**
     * @fileoverview added by tsickle
     * @suppress {checkTypes,extraRequire,missingReturn,unusedPrivateMembers,uselessCode} checked by tsc
     */
    /**
     * \@dynamic
     */
    var SpeechSynthesisUtteranceFactoryService = /** @class */ (function () {
        function SpeechSynthesisUtteranceFactoryService(config, 
        /**
         * This attribute specifies the language of the speech synthesis for the utterance,
         * using a valid BCP 47 language tag.
         * [BCP47] If unset it remains unset for getting in script,
         * but will default to use the language of the html document root element and associated hierarchy.
         * This default value is computed and used when the input request opens a connection
         * to the recognition service.
         */
        lang, 
        /**
         * This attribute specifies the speech synthesis voice that the web application wishes to use.
         * When a SpeechSynthesisUtterance object is created this attribute must be initialized to null.
         * If, at the time of the speak() method call,
         * this attribute has been set to one of the SpeechSynthesisVoice objects returned by getVoices(),
         * then the user agent must use that voice. If this attribute is unset or null at the time of the speak()
         * method call, then the user agent must use a user agent default voice.
         * The user agent default voice should support the current language (see lang) and
         * can be a local or remote speech service and can incorporate end user choices via interfaces
         * provided by the user agent such as browser configuration parameters.
         */
        voice, 
        /**
         * This attribute specifies the speaking volume for the utterance.
         * It ranges between 0 and 1 inclusive, with 0 being the lowest volume and 1 the highest volume,
         * with a default of 1. If SSML is used, this value will be overridden by prosody tags in the markup.
         */
        volume, 
        /**
         * This attribute specifies the speaking rate for the utterance.
         * It is relative to the default rate for this voice.
         * 1 is the default rate supported by the speech synthesis engine or specific voice
         * (which should correspond to a normal speaking rate).
         * 2 is twice as fast, and 0.5 is half as fast. Values below 0.1 or above 10 are strictly disallowed,
         * but speech synthesis engines or specific voices may constrain the minimum and maximum rates further,
         * for example, a particular voice may not actually speak faster than 3 times normal
         * even if you specify a value larger than 3.
         * If SSML is used, this value will be overridden by prosody tags in the markup.
         */
        rate, 
        /**
         * This attribute specifies the speaking pitch for the utterance.
         * It ranges between 0 and 2 inclusive, with 0 being the lowest pitch and 2 the highest pitch.
         * 1 corresponds to the default pitch of the speech synthesis engine or specific voice.
         * Speech synthesis engines or voices may constrain the minimum and maximum rates further.
         * If SSML is used, this value will be overridden by prosody tags in the markup.
         */
        pitch, 
        /**
         * Fired when this utterance has begun to be spoken.
         */
        onstart, 
        /**
         * Fired when this utterance has completed being spoken. If this event fires,
         * the error event must not be fired for this utterance.
         */
        onend, 
        /**
         * Fired if there was an error that prevented successful speaking of this utterance.
         * If this event fires, the end event must not be fired for this utterance.
         */
        onerror, 
        /**
         * Fired when and if this utterance is paused mid-utterance.
         */
        onpause, 
        /**
         * Fired when and if this utterance is resumed after being paused mid-utterance.
         * Adding the utterance to the queue while the global SpeechSynthesis instance is in the paused state,
         * and then calling the resume method does not cause the resume event to be fired,
         * in this case the utterance’s start event will be called when the utterance starts.
         */
        onresume, 
        /**
         * Fired when the spoken utterance reaches a named "mark" tag in SSML.
         * [SSML] The user agent must fire this event if the speech synthesis engine provides the event.
         */
        onmark, 
        /**
         * Fired when the spoken utterance reaches a word or sentence boundary.
         * The user agent must fire this event if the speech synthesis engine provides the event.
         */
        onboundary) {
            var _this = this;
            this.internal = window.speechSynthesis;
            this._config = config;
            this._lang = lang;
            if (typeof voice === 'string') {
                this.internal
                    .addEventListener('voiceschanged', function () {
                    _this._voice = _this.internal
                        .getVoices().find(function (v) { return v.name === voice; });
                });
            }
            else {
                this._voice = voice;
            }
            this._volume = volume;
            this._rate = rate;
            this._pitch = pitch;
            this._onstart = onstart;
            this._onend = onend;
            this._onerror = onerror;
            this._onpause = onpause;
            this._onresume = onresume;
            this._onmark = onmark;
            this._onboundary = onboundary;
        }
        Object.defineProperty(SpeechSynthesisUtteranceFactoryService.prototype, "lang", {
            /**
             * This attribute specifies the language of the speech synthesis for the utterance,
             * using a valid BCP 47 language tag.
             * [BCP47] If unset it remains unset for getting in script,
             * but will default to use the language of the html document root element and associated hierarchy.
             * This default value is computed and used when the input request opens a connection
             * to the recognition service.
             */
            get: /**
             * This attribute specifies the language of the speech synthesis for the utterance,
             * using a valid BCP 47 language tag.
             * [BCP47] If unset it remains unset for getting in script,
             * but will default to use the language of the html document root element and associated hierarchy.
             * This default value is computed and used when the input request opens a connection
             * to the recognition service.
             * @return {?}
             */ function () {
                return this._lang || this._config.lang;
            },
            set: /**
             * @param {?} lang
             * @return {?}
             */ function (lang) {
                this._lang = lang;
            },
            enumerable: true,
            configurable: true
        });
        Object.defineProperty(SpeechSynthesisUtteranceFactoryService.prototype, "voice", {
            /**
             * This attribute specifies the speech synthesis voice that the web application wishes to use.
             * When a SpeechSynthesisUtterance object is created this attribute must be initialized to null.
             * If, at the time of the speak() method call,
             * this attribute has been set to one of the SpeechSynthesisVoice objects returned by getVoices(),
             * then the user agent must use that voice. If this attribute is unset or null at the time of the speak()
             * method call, then the user agent must use a user agent default voice.
             * The user agent default voice should support the current language (see lang) and
             * can be a local or remote speech service and can incorporate end user choices via interfaces
             * provided by the user agent such as browser configuration parameters.
             */
            get: /**
             * This attribute specifies the speech synthesis voice that the web application wishes to use.
             * When a SpeechSynthesisUtterance object is created this attribute must be initialized to null.
             * If, at the time of the speak() method call,
             * this attribute has been set to one of the SpeechSynthesisVoice objects returned by getVoices(),
             * then the user agent must use that voice. If this attribute is unset or null at the time of the speak()
             * method call, then the user agent must use a user agent default voice.
             * The user agent default voice should support the current language (see lang) and
             * can be a local or remote speech service and can incorporate end user choices via interfaces
             * provided by the user agent such as browser configuration parameters.
             * @return {?}
             */ function () {
                return this._voice || this._config.voice;
            },
            set: /**
             * @param {?} voice
             * @return {?}
             */ function (voice) {
                this._voice = voice;
            },
            enumerable: true,
            configurable: true
        });
        Object.defineProperty(SpeechSynthesisUtteranceFactoryService.prototype, "volume", {
            /**
             * This attribute specifies the speaking volume for the utterance.
             * It ranges between 0 and 1 inclusive, with 0 being the lowest volume and 1 the highest volume,
             * with a default of 1. If SSML is used, this value will be overridden by prosody tags in the markup.
             */
            get: /**
             * This attribute specifies the speaking volume for the utterance.
             * It ranges between 0 and 1 inclusive, with 0 being the lowest volume and 1 the highest volume,
             * with a default of 1. If SSML is used, this value will be overridden by prosody tags in the markup.
             * @return {?}
             */ function () {
                return this._volume || this._config.volume;
            },
            set: /**
             * @param {?} volume
             * @return {?}
             */ function (volume) {
                this._volume = volume;
            },
            enumerable: true,
            configurable: true
        });
        Object.defineProperty(SpeechSynthesisUtteranceFactoryService.prototype, "rate", {
            /**
             * This attribute specifies the speaking rate for the utterance.
             * It is relative to the default rate for this voice.
             * 1 is the default rate supported by the speech synthesis engine or specific voice
             * (which should correspond to a normal speaking rate).
             * 2 is twice as fast, and 0.5 is half as fast. Values below 0.1 or above 10 are strictly disallowed,
             * but speech synthesis engines or specific voices may constrain the minimum and maximum rates further,
             * for example, a particular voice may not actually speak faster than 3 times normal
             * even if you specify a value larger than 3.
             * If SSML is used, this value will be overridden by prosody tags in the markup.
             */
            get: /**
             * This attribute specifies the speaking rate for the utterance.
             * It is relative to the default rate for this voice.
             * 1 is the default rate supported by the speech synthesis engine or specific voice
             * (which should correspond to a normal speaking rate).
             * 2 is twice as fast, and 0.5 is half as fast. Values below 0.1 or above 10 are strictly disallowed,
             * but speech synthesis engines or specific voices may constrain the minimum and maximum rates further,
             * for example, a particular voice may not actually speak faster than 3 times normal
             * even if you specify a value larger than 3.
             * If SSML is used, this value will be overridden by prosody tags in the markup.
             * @return {?}
             */ function () {
                return this._rate || this._config.rate;
            },
            set: /**
             * @param {?} rate
             * @return {?}
             */ function (rate) {
                this._rate = rate;
            },
            enumerable: true,
            configurable: true
        });
        Object.defineProperty(SpeechSynthesisUtteranceFactoryService.prototype, "pitch", {
            /**
             * This attribute specifies the speaking pitch for the utterance.
             * It ranges between 0 and 2 inclusive, with 0 being the lowest pitch and 2 the highest pitch.
             * 1 corresponds to the default pitch of the speech synthesis engine or specific voice.
             * Speech synthesis engines or voices may constrain the minimum and maximum rates further.
             * If SSML is used, this value will be overridden by prosody tags in the markup.
             */
            get: /**
             * This attribute specifies the speaking pitch for the utterance.
             * It ranges between 0 and 2 inclusive, with 0 being the lowest pitch and 2 the highest pitch.
             * 1 corresponds to the default pitch of the speech synthesis engine or specific voice.
             * Speech synthesis engines or voices may constrain the minimum and maximum rates further.
             * If SSML is used, this value will be overridden by prosody tags in the markup.
             * @return {?}
             */ function () {
                return this._pitch || this._config.pitch;
            },
            set: /**
             * @param {?} pitch
             * @return {?}
             */ function (pitch) {
                this._pitch = pitch;
            },
            enumerable: true,
            configurable: true
        });
        Object.defineProperty(SpeechSynthesisUtteranceFactoryService.prototype, "onstart", {
            /**
             * Fired when this utterance has begun to be spoken.
             */
            get: /**
             * Fired when this utterance has begun to be spoken.
             * @return {?}
             */ function () {
                return this._onstart || this._config.onstart;
            },
            set: /**
             * @param {?} onstart
             * @return {?}
             */ function (onstart) {
                this._onstart = onstart;
            },
            enumerable: true,
            configurable: true
        });
        Object.defineProperty(SpeechSynthesisUtteranceFactoryService.prototype, "onend", {
            /**
             * Fired when this utterance has completed being spoken. If this event fires,
             * the error event must not be fired for this utterance.
             */
            get: /**
             * Fired when this utterance has completed being spoken. If this event fires,
             * the error event must not be fired for this utterance.
             * @return {?}
             */ function () {
                return this._onend || this._config.onend;
            },
            set: /**
             * @param {?} onend
             * @return {?}
             */ function (onend) {
                this._onend = onend;
            },
            enumerable: true,
            configurable: true
        });
        Object.defineProperty(SpeechSynthesisUtteranceFactoryService.prototype, "onerror", {
            /**
             * Fired if there was an error that prevented successful speaking of this utterance.
             * If this event fires, the end event must not be fired for this utterance.
             */
            get: /**
             * Fired if there was an error that prevented successful speaking of this utterance.
             * If this event fires, the end event must not be fired for this utterance.
             * @return {?}
             */ function () {
                return this._onerror || this._config.onerror;
            },
            set: /**
             * @param {?} onerror
             * @return {?}
             */ function (onerror) {
                this._onerror = onerror;
            },
            enumerable: true,
            configurable: true
        });
        Object.defineProperty(SpeechSynthesisUtteranceFactoryService.prototype, "onpause", {
            /**
             * Fired when and if this utterance is paused mid-utterance.
             */
            get: /**
             * Fired when and if this utterance is paused mid-utterance.
             * @return {?}
             */ function () {
                return this._onpause || this._config.onpause;
            },
            set: /**
             * @param {?} onpause
             * @return {?}
             */ function (onpause) {
                this._onpause = onpause;
            },
            enumerable: true,
            configurable: true
        });
        Object.defineProperty(SpeechSynthesisUtteranceFactoryService.prototype, "onresume", {
            /**
             * Fired when and if this utterance is resumed after being paused mid-utterance.
             * Adding the utterance to the queue while the global SpeechSynthesis instance is in the paused state,
             * and then calling the resume method does not cause the resume event to be fired,
             * in this case the utterance’s start event will be called when the utterance starts.
             */
            get: /**
             * Fired when and if this utterance is resumed after being paused mid-utterance.
             * Adding the utterance to the queue while the global SpeechSynthesis instance is in the paused state,
             * and then calling the resume method does not cause the resume event to be fired,
             * in this case the utterance’s start event will be called when the utterance starts.
             * @return {?}
             */ function () {
                return this._onresume || this._config.onresume;
            },
            set: /**
             * @param {?} onresume
             * @return {?}
             */ function (onresume) {
                this._onresume = onresume;
            },
            enumerable: true,
            configurable: true
        });
        Object.defineProperty(SpeechSynthesisUtteranceFactoryService.prototype, "onmark", {
            /**
             * Fired when the spoken utterance reaches a named "mark" tag in SSML.
             * [SSML] The user agent must fire this event if the speech synthesis engine provides the event.
             */
            get: /**
             * Fired when the spoken utterance reaches a named "mark" tag in SSML.
             * [SSML] The user agent must fire this event if the speech synthesis engine provides the event.
             * @return {?}
             */ function () {
                return this._onmark || this._config.onmark;
            },
            set: /**
             * @param {?} onmark
             * @return {?}
             */ function (onmark) {
                this._onmark = onmark;
            },
            enumerable: true,
            configurable: true
        });
        Object.defineProperty(SpeechSynthesisUtteranceFactoryService.prototype, "onboundary", {
            /**
             * Fired when the spoken utterance reaches a word or sentence boundary.
             * The user agent must fire this event if the speech synthesis engine provides the event.
             */
            get: /**
             * Fired when the spoken utterance reaches a word or sentence boundary.
             * The user agent must fire this event if the speech synthesis engine provides the event.
             * @return {?}
             */ function () {
                return this._onboundary || this._config.onboundary;
            },
            set: /**
             * @param {?} onboundary
             * @return {?}
             */ function (onboundary) {
                this._onboundary = onboundary;
            },
            enumerable: true,
            configurable: true
        });
        /**
         * This attribute specifies the text to be synthesized and spoken for this utterance.
         * This may be either plain text or a complete, well-formed SSML document.
         * [SSML] For speech synthesis engines that do not support SSML,
         * or only support certain tags, the user agent or speech engine must strip away
         * the tags they do not support and speak the text. There may be a maximum length of the text,
         * it may be limited to 32,767 characters.
         */
        /**
         * This attribute specifies the text to be synthesized and spoken for this utterance.
         * This may be either plain text or a complete, well-formed SSML document.
         * [SSML] For speech synthesis engines that do not support SSML,
         * or only support certain tags, the user agent or speech engine must strip away
         * the tags they do not support and speak the text. There may be a maximum length of the text,
         * it may be limited to 32,767 characters.
         * @param {?} text
         * @return {?}
         */
        SpeechSynthesisUtteranceFactoryService.prototype.text = /**
         * This attribute specifies the text to be synthesized and spoken for this utterance.
         * This may be either plain text or a complete, well-formed SSML document.
         * [SSML] For speech synthesis engines that do not support SSML,
         * or only support certain tags, the user agent or speech engine must strip away
         * the tags they do not support and speak the text. There may be a maximum length of the text,
         * it may be limited to 32,767 characters.
         * @param {?} text
         * @return {?}
         */
            function (text) {
                /** @type {?} */
                var utterance = new SpeechSynthesisUtterance(text);
                utterance.lang = this.lang;
                utterance.voice = this.voice;
                utterance.volume = this.volume;
                utterance.rate = this.rate;
                utterance.pitch = this.pitch;
                utterance.onstart = this.onstart;
                utterance.onend = this.onend;
                utterance.onerror = this.onerror;
                utterance.onpause = this.onpause;
                utterance.onresume = this.onresume;
                utterance.onmark = this.onmark;
                utterance.onboundary = this.onboundary;
                return utterance;
            };
        SpeechSynthesisUtteranceFactoryService.decorators = [
            { type: i0.Injectable, args: [{
                        providedIn: 'root'
                    },] }
        ];
        /** @nocollapse */
        SpeechSynthesisUtteranceFactoryService.ctorParameters = function () {
            return [
                { type: undefined, decorators: [{ type: i0.Optional }, { type: i0.Inject, args: [Config,] }] },
                { type: String, decorators: [{ type: i0.Optional }, { type: i0.Inject, args: [Lang,] }] },
                { type: undefined, decorators: [{ type: i0.Optional }, { type: i0.Inject, args: [Voice,] }] },
                { type: Number, decorators: [{ type: i0.Optional }, { type: i0.Inject, args: [Volume,] }] },
                { type: Number, decorators: [{ type: i0.Optional }, { type: i0.Inject, args: [Rate,] }] },
                { type: Number, decorators: [{ type: i0.Optional }, { type: i0.Inject, args: [Pitch,] }] },
                { type: undefined, decorators: [{ type: i0.Optional }, { type: i0.Inject, args: [OnStartHandler,] }] },
                { type: undefined, decorators: [{ type: i0.Optional }, { type: i0.Inject, args: [OnEndHandler,] }] },
                { type: undefined, decorators: [{ type: i0.Optional }, { type: i0.Inject, args: [OnErrorHandler,] }] },
                { type: undefined, decorators: [{ type: i0.Optional }, { type: i0.Inject, args: [OnPauseHandler,] }] },
                { type: undefined, decorators: [{ type: i0.Optional }, { type: i0.Inject, args: [OnResumeHandler,] }] },
                { type: undefined, decorators: [{ type: i0.Optional }, { type: i0.Inject, args: [OnMarkHandler,] }] },
                { type: undefined, decorators: [{ type: i0.Optional }, { type: i0.Inject, args: [OnBoundaryHandler,] }] }
            ];
        };
        /** @nocollapse */ SpeechSynthesisUtteranceFactoryService.ngInjectableDef = i0.defineInjectable({ factory: function SpeechSynthesisUtteranceFactoryService_Factory() { return new SpeechSynthesisUtteranceFactoryService(i0.inject(Config, 8), i0.inject(Lang, 8), i0.inject(Voice, 8), i0.inject(Volume, 8), i0.inject(Rate, 8), i0.inject(Pitch, 8), i0.inject(OnStartHandler, 8), i0.inject(OnEndHandler, 8), i0.inject(OnErrorHandler, 8), i0.inject(OnPauseHandler, 8), i0.inject(OnResumeHandler, 8), i0.inject(OnMarkHandler, 8), i0.inject(OnBoundaryHandler, 8)); }, token: SpeechSynthesisUtteranceFactoryService, providedIn: "root" });
        return SpeechSynthesisUtteranceFactoryService;
    }());

    /**
     * @fileoverview added by tsickle
     * @suppress {checkTypes,extraRequire,missingReturn,unusedPrivateMembers,uselessCode} checked by tsc
     */
    var SpeechSynthesisModule = /** @class */ (function () {
        function SpeechSynthesisModule() {
        }
        /**
         * @param {?} config
         * @return {?}
         */
        SpeechSynthesisModule.forRoot = /**
         * @param {?} config
         * @return {?}
         */
            function (config) {
                return {
                    ngModule: SpeechSynthesisModule,
                    providers: [
                        {
                            provide: Config,
                            useValue: config,
                        },
                    ],
                };
            };
        SpeechSynthesisModule.decorators = [
            { type: i0.NgModule, args: [{
                        declarations: [],
                        imports: [],
                        exports: []
                    },] }
        ];
        return SpeechSynthesisModule;
    }());

    /**
     * @fileoverview added by tsickle
     * @suppress {checkTypes,extraRequire,missingReturn,unusedPrivateMembers,uselessCode} checked by tsc
     */

    /**
     * @fileoverview added by tsickle
     * @suppress {checkTypes,extraRequire,missingReturn,unusedPrivateMembers,uselessCode} checked by tsc
     */
    /* tslint:disable */
    /** @type {?} */
    var SpeechSynthesisVoice = window['SpeechSynthesisVoice'];

    /**
     * @fileoverview added by tsickle
     * @suppress {checkTypes,extraRequire,missingReturn,unusedPrivateMembers,uselessCode} checked by tsc
     */

    exports.Lang = Lang;
    exports.Voice = Voice;
    exports.Volume = Volume;
    exports.Rate = Rate;
    exports.Pitch = Pitch;
    exports.OnStartHandler = OnStartHandler;
    exports.OnEndHandler = OnEndHandler;
    exports.OnErrorHandler = OnErrorHandler;
    exports.OnPauseHandler = OnPauseHandler;
    exports.OnResumeHandler = OnResumeHandler;
    exports.OnMarkHandler = OnMarkHandler;
    exports.OnBoundaryHandler = OnBoundaryHandler;
    exports.Params = Params;
    exports.Config = Config;
    exports.SpeechSynthesisService = SpeechSynthesisService;
    exports.SpeechSynthesisUtteranceFactoryService = SpeechSynthesisUtteranceFactoryService;
    exports.SpeechSynthesisModule = SpeechSynthesisModule;
    exports.ɵa = SpeechSynthesisVoice;

    Object.defineProperty(exports, '__esModule', { value: true });

})));

//# sourceMappingURL=kamiazya-ngx-speech-synthesis.umd.js.map